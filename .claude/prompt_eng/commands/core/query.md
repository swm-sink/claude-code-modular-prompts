| version | last_updated | status |
|---------|--------------|--------|
| 3.0.0   | 2025-07-08   | stable |

# /query - LEAP/CLEAR advanced research & analysis (Zero Modifications)

────────────────────────────────────────────────────────────────────────────────


────────────────────────────────────────────────────────────────────────────────

> **⚡ Clear Purpose**: Researches and explains code WITHOUT creating any files. Want to CREATE documentation? Use `/docs` instead!

────────────────────────────────────────────────────────────────────────────────

```xml
<command purpose="LEAP/CLEAR framework research and comprehensive analysis with zero modifications">
  
  <delegation target="modules/development/research-analysis.md">
    LEAP learning framework → CLEAR comprehensive analysis → Parallel search → Deep investigation → Pattern mapping → Research report
  </delegation>
  
  <pattern_integration>
    <uses_pattern from="patterns/research-analysis-pattern.md">Systematic knowledge discovery</uses_pattern>
    <uses_pattern from="patterns/critical-thinking-pattern.md">Framework-guided analysis approach</uses_pattern>
    <uses_pattern from="patterns/context-management-pattern.md">Research context optimization</uses_pattern>
    <uses_pattern from="patterns/performance-optimization-pattern.md">Parallel search operations</uses_pattern>
    <uses_pattern from="patterns/user-interaction-pattern.md">Knowledge transfer optimization</uses_pattern>
    <uses_pattern from="patterns/documentation-pattern.md">Research methodology and presentation</uses_pattern>
  </pattern_integration>
  
  <thinking_pattern enforcement="MANDATORY">
    <checkpoint id="1" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply LEAP framework - Learn query requirements and research objectives</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What learning objective analysis is needed for optimal research approach?
          - What context and constraints apply to this knowledge acquisition?
          - How does learning requirement connect to research methodology and delivery?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Knowledge Question: What specific knowledge or understanding is being sought through this query?]
          - [Learning Question: What learning objectives will drive the research approach and methodology?]
          - [Gap Question: What existing knowledge gaps need to be filled through systematic investigation?]
          - [Scope Question: How does the learning requirement guide research scope and depth priorities?]
          - [Purpose Question: Is this request for learning analysis (query) vs creating artifacts (docs command)?]
          - [Framework Question: How does LEAP framework optimize this learning approach?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this learning approach optimal for the query characteristics?
          - What evidence supports the research methodology selection?
          - How will this approach maximize knowledge acquisition success?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can learning analysis be combined with initial research preparation?</tool_optimization>
        <context_efficiency>How can learning objectives optimize context window usage?</context_efficiency>
        <dependency_analysis>What objective analysis is sequential vs parallel for research setup?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>LEAP_LEARNING_OBJECTIVES:
        - Knowledge target: [specific_information_sought]
        - Learning scope: [breadth_and_depth_requirements]
        - Research methodology: [investigation_approach]
        - Expected outcomes: [knowledge_deliverables]</output_format>
      <validation>Learning objectives clearly defined to guide systematic research approach with enhanced reasoning</validation>
      <enforcement>BLOCK if query requests modifications - must be pure research and learning</enforcement>
      <context_transfer>Learning objectives and methodology for exploration strategy</context_transfer>
    </checkpoint>
    <checkpoint id="2" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply LEAP framework - Explore codebase systematically for comprehensive knowledge</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What exploration strategy will optimize knowledge discovery?
          - What parallel search approach maximizes learning efficiency?
          - How does exploration connect to learning objectives and knowledge targets?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Strategy Question: What exploration strategy will discover the most relevant knowledge efficiently?]
          - [Parallel Question: Which parallel search operations maximize learning while minimizing exploration time?]
          - [Prioritization Question: How should exploration prioritize different types of sources (implementation, tests, docs)?]
          - [Coverage Question: What systematic approach ensures comprehensive coverage without redundant exploration?]
          - [Alignment Question: How does exploration align with learning objectives and knowledge targets?]
          - [Efficiency Question: How can exploration be optimized for 70% performance improvement?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this exploration strategy optimal for the learning objectives?
          - What evidence supports the parallel search approach?
          - How will this exploration maximize knowledge discovery success?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can exploration operations be batched for 70% improvement (Read, Grep, analysis)?</tool_optimization>
        <context_efficiency>How can exploration optimize context window usage for learning?</context_efficiency>
        <dependency_analysis>What exploration can be done in parallel vs sequential for knowledge discovery?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>LEAP_EXPLORATION_STRATEGY:
        - Search approach: [parallel_operations_for_70%_improvement]
        - Source prioritization: [implementation_tests_docs_architecture]
        - Coverage methodology: [systematic_exploration_patterns]
        - Knowledge discovery: [learning_focused_investigation]</output_format>
      <validation>Exploration systematically structured for optimal knowledge discovery and learning with enhanced reasoning</validation>
      <enforcement>VERIFY parallel execution used for 70% performance improvement in exploration</enforcement>
      <context_transfer>Exploration strategy and findings for knowledge synthesis</context_transfer>
    </checkpoint>
    <checkpoint id="3" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply LEAP framework - Apply knowledge synthesis and pattern recognition</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What knowledge synthesis approach will optimize understanding?
          - What pattern recognition strategy reveals architectural insights?
          - How does knowledge application connect to learning objectives and analysis depth?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Synthesis Question: How should discovered information be synthesized into coherent knowledge?]
          - [Pattern Question: What patterns emerge from the exploration that advance learning objectives?]
          - [Integration Question: How do different sources of information integrate to form comprehensive understanding?]
          - [Insight Question: What connections and relationships reveal deeper architectural or design insights?]
          - [Application Question: How does knowledge application guide further exploration or analysis focus?]
          - [Depth Question: What synthesis approach ensures maximum learning value?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this knowledge synthesis optimal for the learning objectives?
          - What evidence supports the pattern recognition approach?
          - How will this synthesis maximize understanding and insight development?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can knowledge synthesis be optimized for parallel pattern analysis?</tool_optimization>
        <context_efficiency>How can synthesis optimize context window usage for understanding?</context_efficiency>
        <dependency_analysis>What synthesis tasks can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>LEAP_KNOWLEDGE_APPLICATION:
        - Information synthesis: [coherent_knowledge_integration]
        - Pattern recognition: [architectural_and_design_patterns]
        - Relationship mapping: [component_and_dependency_connections]
        - Insight development: [deeper_understanding_achievements]</output_format>
      <validation>Knowledge systematically applied and synthesized for comprehensive understanding with enhanced reasoning</validation>
      <enforcement>ENSURE application depth matches learning objectives and query complexity</enforcement>
      <context_transfer>Knowledge synthesis and patterns for production deliverables</context_transfer>
    </checkpoint>
    <checkpoint id="4" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply LEAP framework - Produce comprehensive knowledge deliverables</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What knowledge production approach will optimize learning value?
          - What deliverable format maximizes learning usability?
          - How does knowledge production connect to learning objectives and user needs?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Format Question: What knowledge production format best serves the learning objectives?]
          - [Structure Question: How should findings be structured to maximize learning value and usability?]
          - [Evidence Question: What concrete examples and evidence support the knowledge deliverables?]
          - [Alignment Question: How does knowledge production align with original learning requirements?]
          - [Transfer Question: What level of detail and explanation optimizes knowledge transfer?]
          - [Value Question: What production approach ensures maximum learning impact?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this knowledge production optimal for the learning objectives?
          - What evidence supports the deliverable format selection?
          - How will this production approach maximize knowledge transfer success?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can knowledge production be optimized for parallel deliverable creation?</tool_optimization>
        <context_efficiency>How can production optimize context window usage for learning delivery?</context_efficiency>
        <dependency_analysis>What production tasks can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>LEAP_KNOWLEDGE_PRODUCTION:
        - Deliverable format: [optimal_knowledge_presentation]
        - Structure approach: [learning_optimized_organization]
        - Evidence integration: [concrete_examples_and_code_references]
        - Knowledge validation: [learning_objective_fulfillment]</output_format>
      <validation>Knowledge production optimized for learning value and objective fulfillment with enhanced reasoning</validation>
      <enforcement>CRITICAL: ZERO modifications - pure knowledge production and learning delivery</enforcement>
      <context_transfer>Knowledge deliverables for CLEAR framework context analysis</context_transfer>
    </checkpoint>
    <checkpoint id="5" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply CLEAR framework - Comprehensive Context analysis for research</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What context analysis approach will enhance research accuracy?
          - What comprehensive context dimensions affect knowledge interpretation?
          - How does context analysis connect to learning objectives and research reliability?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Comprehensiveness Question: What comprehensive context affects the accuracy and completeness of research findings?]
          - [Technical Question: What technical, architectural, and business context influences knowledge interpretation?]
          - [Historical Question: What historical context (git history, evolution) provides deeper understanding?]
          - [Ecosystem Question: What ecosystem context (dependencies, integrations) affects knowledge relevance?]
          - [Enhancement Question: How does context analysis enhance learning objective achievement?]
          - [Reliability Question: What context analysis ensures maximum research reliability?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this context analysis optimal for research accuracy?
          - What evidence supports the comprehensive context approach?
          - How will this analysis maximize learning objective achievement?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can context analysis be parallelized for efficiency improvement?</tool_optimization>
        <context_efficiency>How can analysis optimize context window usage for research?</context_efficiency>
        <dependency_analysis>What context analysis can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>CLEAR_RESEARCH_CONTEXT:
        - Technical context: [architecture_patterns_and_implementation_context]
        - Business context: [domain_requirements_and_business_logic_context]
        - Historical context: [evolution_and_development_history_insights]
        - Ecosystem context: [dependencies_integrations_and_external_factors]</output_format>
      <validation>Context comprehensively analyzed to enhance research accuracy and learning value with enhanced reasoning</validation>
      <enforcement>BLOCK if context analysis incomplete for reliable knowledge production</enforcement>
      <context_transfer>Context analysis for limitation identification</context_transfer>
    </checkpoint>
    <checkpoint id="6" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply CLEAR framework - Identify Limitations and research constraints</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What limitation identification approach ensures research integrity?
          - What constraint analysis supports knowledge reliability?
          - How does limitation identification connect to research honesty and accuracy?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Information Question: What limitations in available information affect research conclusions accuracy?]
          - [Scope Question: What constraints in codebase access or analysis scope impact knowledge completeness?]
          - [Understanding Question: What limitations in current understanding require acknowledgment or further investigation?]
          - [Methodology Question: How do research methodology limitations affect knowledge reliability and validity?]
          - [Confidence Question: What boundaries exist around knowledge claims and research confidence levels?]
          - [Integrity Question: What limitation identification ensures maximum research integrity?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this limitation identification optimal for research integrity?
          - What evidence supports the constraint analysis approach?
          - How will this identification maximize knowledge reliability?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can limitation identification be optimized for comprehensive analysis?</tool_optimization>
        <context_efficiency>How can identification optimize context window usage for integrity?</context_efficiency>
        <dependency_analysis>What limitation analysis can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>CLEAR_RESEARCH_LIMITATIONS:
        - Information limitations: [gaps_and_unavailable_data]
        - Scope constraints: [analysis_boundaries_and_restrictions]
        - Methodology limitations: [research_approach_constraints]
        - Confidence boundaries: [knowledge_reliability_levels]</output_format>
      <validation>Limitations transparently identified to ensure research integrity and knowledge accuracy with enhanced reasoning</validation>
      <enforcement>BLOCK if limitations not acknowledged - research must be honest about constraints</enforcement>
      <context_transfer>Limitation identification for example provision</context_transfer>
    </checkpoint>
    <checkpoint id="7" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply CLEAR framework - Provide Examples and concrete evidence</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What example provision approach best supports research findings?
          - What concrete evidence strategy enhances learning comprehension?
          - How does example provision connect to knowledge claims and learning value?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Illustration Question: What specific examples best illustrate the research findings and knowledge discoveries?]
          - [Evidence Question: What concrete code examples provide evidence for patterns and insights identified?]
          - [Implementation Question: What real implementation examples demonstrate the knowledge in practical context?]
          - [Learning Question: How do examples enhance learning value and knowledge comprehension?]
          - [Variety Question: What variety of examples ensures comprehensive knowledge illustration?]
          - [Support Question: What example provision ensures maximum knowledge support?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this example provision optimal for research findings support?
          - What evidence supports the concrete evidence approach?
          - How will this provision maximize learning comprehension?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can example provision be optimized for parallel evidence gathering?</tool_optimization>
        <context_efficiency>How can provision optimize context window usage for learning?</context_efficiency>
        <dependency_analysis>What example provision can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>CLEAR_RESEARCH_EXAMPLES:
        - Code examples: [specific_implementation_demonstrations]
        - Pattern examples: [architectural_and_design_pattern_illustrations]
        - Usage examples: [practical_application_demonstrations]
        - Evidence integration: [concrete_support_for_research_findings]</output_format>
      <validation>Examples comprehensively selected to support research findings and enhance learning with enhanced reasoning</validation>
      <enforcement>ENSURE examples directly support knowledge claims with concrete evidence</enforcement>
      <context_transfer>Example provision for actionable insights</context_transfer>
    </checkpoint>
    <checkpoint id="8" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply CLEAR framework - Define Actions for knowledge application</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What action definition approach maximizes research knowledge value?
          - What actionable insight strategy supports practical application?
          - How does action definition connect to learning objectives and research utility?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Enablement Question: What actions does this research knowledge enable or inform for the user?]
          - [Application Question: How can research findings be applied practically in development or understanding contexts?]
          - [Steps Question: What next steps or follow-up investigations does this knowledge suggest?]
          - [Guidance Question: How do research insights guide decision-making or further exploration?]
          - [Value Question: What actionable value emerges from the comprehensive research and analysis?]
          - [Utility Question: What action definition ensures maximum research utility?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this action definition optimal for research knowledge application?
          - What evidence supports the actionable insight approach?
          - How will this definition maximize practical research value?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can action definition be optimized for parallel insight development?</tool_optimization>
        <context_efficiency>How can definition optimize context window usage for application?</context_efficiency>
        <dependency_analysis>What action definition can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>CLEAR_ACTIONABLE_INSIGHTS:
        - Practical applications: [how_knowledge_can_be_applied]
        - Decision support: [insights_that_inform_development_choices]
        - Further research: [additional_investigation_opportunities]
        - Immediate value: [actionable_knowledge_for_current_work]</output_format>
      <validation>Actions clearly defined to maximize practical value of research knowledge with enhanced reasoning</validation>
      <enforcement>ENSURE actionable insights align with learning objectives and research findings</enforcement>
      <context_transfer>Actionable insights for research delivery</context_transfer>
    </checkpoint>
    <checkpoint id="9" verify="true" enforcement="BLOCKING" thinking_mode="interleaved">
      <action>Apply CLEAR framework - Role-appropriate research delivery and knowledge transfer</action>
      <interleaved_thinking enforcement="MANDATORY">
        <pre_analysis>
          - What delivery approach optimizes knowledge transfer and learning value?
          - What role-appropriate strategy enhances knowledge accessibility?
          - How does delivery optimization connect to learning outcomes and user needs?
        </pre_analysis>
        <critical_thinking minimum_time="30_seconds">
          - [Role Question: What expert role and perspective optimizes knowledge transfer and learning value?]
          - [Presentation Question: How should research findings be presented for maximum comprehension and utility?]
          - [Depth Question: What level of technical depth and explanation serves the user's learning needs best?]
          - [Enhancement Question: How does role-appropriate delivery enhance knowledge accessibility and application?]
          - [Communication Question: What communication approach maximizes research value and learning outcome achievement?]
          - [Optimization Question: What delivery approach ensures maximum knowledge transfer success?]
        </critical_thinking>
        <decision_reasoning>
          - Why is this delivery approach optimal for knowledge transfer?
          - What evidence supports the role-appropriate strategy?
          - How will this delivery maximize learning outcome achievement?
        </decision_reasoning>
      </interleaved_thinking>
      <parallel_execution_considerations>
        <tool_optimization>Can delivery optimization be enhanced for parallel knowledge transfer?</tool_optimization>
        <context_efficiency>How can delivery optimize context window usage for learning?</context_efficiency>
        <dependency_analysis>What delivery tasks can be done in parallel vs sequential?</dependency_analysis>
      </parallel_execution_considerations>
      <output_format>CLEAR_RESEARCH_DELIVERY:
        - Expert perspective: [domain_expertise_and_knowledge_depth]
        - Communication approach: [optimal_knowledge_transfer_method]
        - Technical level: [appropriate_depth_and_complexity]
        - Learning optimization: [maximum_value_knowledge_delivery]</output_format>
      <validation>Research delivery optimized for user learning and knowledge application success with enhanced reasoning</validation>
      <enforcement>BLOCK if delivery approach doesn't optimize learning value and knowledge transfer</enforcement>
      <context_transfer>Complete research delivery with knowledge transfer optimization</context_transfer>
    </checkpoint>
  </thinking_pattern>
  
  <leap_framework_integration enforcement="MANDATORY">
    <learning_objectives>Define specific knowledge targets and research methodology for systematic investigation</learning_objectives>
    <exploration_strategy>Systematic codebase exploration with parallel operations for optimal knowledge discovery</exploration_strategy>
    <knowledge_application>Synthesis and pattern recognition for comprehensive understanding and insight development</knowledge_application>
    <knowledge_production>Optimal deliverable format and structure for maximum learning value and knowledge transfer</knowledge_production>
    <research_methodology>Structured learning approach optimized for knowledge acquisition and comprehension</research_methodology>
    <validation>Reference frameworks/leap.md for complete LEAP framework implementation in research and analysis</validation>
  </leap_framework_integration>
  
  <clear_framework_integration enforcement="MANDATORY">
    <research_context>Comprehensive context analysis across technical, business, historical, and ecosystem dimensions</research_context>
    <limitation_identification>Transparent constraints and boundaries for research integrity and knowledge accuracy</limitation_identification>
    <evidence_provision>Concrete examples and code demonstrations supporting research findings and insights</evidence_provision>
    <actionable_insights>Practical applications and decision support derived from comprehensive research analysis</actionable_insights>
    <expert_delivery>Role-appropriate knowledge transfer optimized for learning value and comprehension</expert_delivery>
    <research_integrity>Honest limitation acknowledgment and reliable knowledge production standards</research_integrity>
    <validation>Reference frameworks/clear.md for complete CLEAR framework implementation in comprehensive research</validation>
  </clear_framework_integration>
  
  <examples>
    /query "How does authentication work?"  # LEAP learning objectives → CLEAR comprehensive analysis → Auth patterns research
    /query "Find Repository pattern uses"   # LEAP systematic exploration → CLEAR evidence examples → Pattern usage analysis
    /query "Identify security issues"       # LEAP knowledge synthesis → CLEAR context analysis → Security research (NO modifications)
    /query "Performance bottlenecks"        # LEAP learning methodology → CLEAR actionable insights → Performance analysis
    /query "Explain the data flow"          # LEAP knowledge production → CLEAR expert delivery → Architecture investigation
    /query "Understand testing strategy"    # LEAP exploration strategy → CLEAR limitation awareness → TDD pattern analysis
  </examples>
  
  <anti_examples>
    ❌ /query "create API documentation"         # Use /docs instead!
    ❌ /query "generate setup guide"             # Use /docs instead!
    ❌ /query "write security guidelines"        # Use /docs instead!
    ✅ /query "how does the security system work?" # Perfect for research!
  </anti_examples>
  
  <rules enforcement="STRICT">
    <rule priority="CRITICAL">ALWAYS apply LEAP framework for systematic learning and knowledge acquisition</rule>
    <rule priority="CRITICAL">ALWAYS apply CLEAR framework for comprehensive research context and analysis</rule>
    <rule priority="CRITICAL">ZERO modifications - read-only analysis and learning ONLY</rule>
    <rule priority="HIGH">Use parallel tool calls for 70% search efficiency improvement</rule>
    <rule priority="HIGH">Comprehensive analysis with concrete examples and evidence</rule>
    <rule priority="HIGH">Framework-guided research integrity with limitation acknowledgment</rule>
    <rule priority="MEDIUM">Framework selection intelligence for research optimization</rule>
  </rules>
  
  <tdd_integration enforcement="MANDATORY">
    <leap_aware_analysis>LEAP learning methodology includes TDD pattern analysis for comprehensive understanding</leap_aware_analysis>
    <clear_test_analysis>CLEAR framework context includes existing test files and TDD patterns for complete research</clear_test_analysis>
    <read_only_research>No TDD enforcement needed - pure knowledge acquisition and learning delivery</read_only_research>
    <test_pattern_learning>Include existing test files in LEAP exploration for enhanced knowledge discovery</test_pattern_learning>
    <framework_integration>TDD awareness integrated with LEAP/CLEAR research methodology</framework_integration>
    <validation>Reference quality/tdd.md#analysis_patterns for framework-integrated test-aware research</validation>
    <blocking_conditions>
      <condition>LEAP framework learning objectives incomplete before research execution</condition>
      <condition>CLEAR framework context analysis bypassed for research integrity</condition>
      <condition>Any attempt to modify files or create new code during research</condition>
      <condition>Query requesting code generation rather than LEAP/CLEAR knowledge acquisition</condition>
      <condition>Research conclusions exceeding CLEAR framework limitation boundaries</condition>
      <condition>Framework compliance bypassed for expedited but incomplete research</condition>
    </blocking_conditions>
  </tdd_integration>
  
  <module_execution enforcement="MANDATORY">
    <core_stack order="sequential">
      <module>quality/critical-thinking.md - 30-second analysis before framework-guided research approach</module>
      <module>frameworks/leap.md - LEAP framework learning methodology for systematic knowledge acquisition</module>
      <module>frameworks/clear.md - CLEAR framework comprehensive analysis for research context and integrity</module>
      <module>development/research-analysis.md - Framework-integrated comprehensive analysis workflow</module>
      <module>patterns/pattern-library.md - Pattern recognition and search strategies with framework optimization</module>
      <module>quality/tdd.md - Test-aware analysis integrated with framework methodology</module>
    </core_stack>
    <contextual_modules>
      <conditional module="frameworks/framework-selector.md" condition="complex_research_requirements"/>
      <conditional module="frameworks/advanced-frameworks.md" condition="specialized_research_needs"/>
      <conditional module="patterns/intelligent-routing.md" condition="query_scope_unclear"/>
      <conditional module="security/threat-modeling.md" condition="security_analysis"/>
      <conditional module="development/documentation.md" condition="documentation_analysis"/>
    </contextual_modules>
  </module_execution>
  
  <pattern_usage>
    • Uses leap_framework_integration pattern for systematic learning and knowledge acquisition methodology
    • Implements clear_framework_integration pattern for comprehensive research context and analysis integrity
    • Applies framework_selection_intelligence pattern for research optimization strategies
    • Uses parallel_execution for Grep/Glob operations with LEAP exploration strategy (70% faster)
    • Implements smart_memoization for repeated queries with CLEAR limitation awareness
    • Applies three_x_rule for thorough LEAP knowledge synthesis and analysis
    • Leverages consequence_mapping for CLEAR actionable insights and impact assessment
    • Uses pattern-library.md search patterns with framework optimization
    • Integrates research_methodology patterns with framework-guided knowledge production
    
    See modules/frameworks/leap.md for LEAP framework learning methodology implementation
    See modules/frameworks/clear.md for CLEAR framework comprehensive research implementation
    See modules/frameworks/framework-selector.md for research optimization intelligence
    See modules/patterns/pattern-library.md for framework-integrated pattern details
    See modules/development/research-analysis.md for LEAP/CLEAR integrated full implementation
  </pattern_usage>
  

  <prompt_construction>
    <assembly_preview>
      WORKFLOW ASSEMBLY:
      ┌─────────────────┐
      │ 1. Query       │ → Parse research intent
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │    Analysis    │
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │ 2. Parallel    │ → Multi-source search
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │    Search      │
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │ 3. Deep        │ → Pattern analysis
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │    Analysis    │
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │ 4. Report      │ → Comprehensive findings
      └────────┬────────┘
               ↓
      ┌─────────────────┐
      │    Generation  │
      └─────────────────┘
    </assembly_preview>

    <context_budget>
      Estimated tokens: ~10,000
      - Query parsing: 1,000
      - Parallel search: 4,000
      - Deep analysis: 3,500
      - Report generation: 1,500
    </context_budget>
  </prompt_construction>

  <runtime_visualization>
    <execution_trace>
      [00:00] ▶️ START: /query "How does auth work?"
      [00:15] 🔍 ANALYSIS: Authentication system research
      [00:30] 🔄 SEARCH: Parallel scanning auth modules...
      [01:00] 📊 ANALYSIS: Found 3 auth patterns, analyzing...
      [01:30] 📝 REPORT: Comprehensive auth analysis complete
      [01:35] ✅ COMPLETE: Research findings delivered
    </execution_trace>
  </runtime_visualization>

  <claude_4_interpretation>
    <parsing_behavior>
      1. Reads checkpoint structure sequentially
      2. Executes critical_thinking questions internally
      3. Formats output according to output_format specifications
      4. Validates against enforcement rules before proceeding
      5. Applies parallel execution optimization where possible
    </parsing_behavior>

    <decision_points>
      - Checkpoint failures trigger enforcement actions
      - Module selection based on contextual conditions
      - Parallel execution for independent operations
      - Quality gate validation at completion boundaries
      - Error recovery through graceful degradation paths
    </decision_points>
  </claude_4_interpretation>

</command>
```