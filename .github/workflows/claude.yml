name: Claude Code AI Assistant Integration

"on":
  issue_comment:
    types: [created]
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - '.claude/**'
      - 'CLAUDE.md'
  workflow_dispatch:
    inputs:
      mode:
        description: 'Execution mode'
        required: true
        default: 'claude-standard'
        type: choice
        options:
        - claude-standard
        - claude-framework
        - claude-maintenance
        - claude-prompt-review
      comment:
        description: 'Custom command or comment'
        required: false
        type: string
      review_mode:
        description: 'Prompt review mode'
        required: false
        default: 'auto'
        type: choice
        options:
        - auto
        - manual
        - force-approve
  schedule:
    # Run maintenance checks daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  # Global environment variables
  CLAUDE_CONFIG_PATH: '.claude'
  FRAMEWORK_VERSION: 'v7.0.0-EMPIRICAL-REALITY-ALIGNED'
  PYTHON_VERSION: '3.11'

jobs:
  # Basic Claude Code integration with minimal permissions
  claude-standard:
    name: 'Claude Code Standard Mode'
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'issue_comment' && 
       contains(github.event.comment.body, '@claude') && 
       !contains(github.event.comment.body, '@claude-framework')) ||
      (github.event_name == 'workflow_dispatch' && 
       github.event.inputs.mode == 'claude-standard')
    
    permissions:
      contents: write
      issues: write
      pull-requests: write
      actions: read
      
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Install Claude Code CLI
        run: |
          curl -fsSL https://claude.ai/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          
      - name: Verify Claude Code installation
        run: |
          claude --version
          
      - name: Set up Claude Code configuration
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Configure Claude Code with standard permissions
          claude configure --api-key="$ANTHROPIC_API_KEY"
          
      - name: Extract command from comment
        if: github.event_name == 'issue_comment'
        id: extract-command
        run: |
          COMMENT_BODY="${{ github.event.comment.body }}"
          COMMAND=$(echo "$COMMENT_BODY" | grep -oP '@claude\s+\K.*' || echo "help")
          echo "command=$COMMAND" >> $GITHUB_OUTPUT
          
      - name: Execute Claude Code command
        env:
          CLAUDE_COMMAND: ${{ steps.extract-command.outputs.command || github.event.inputs.comment || 'help' }}
        run: |
          echo "Executing Claude Code in standard mode..."
          echo "Command: $CLAUDE_COMMAND"
          
          # Execute with standard safety boundaries
          claude --mode=standard "$CLAUDE_COMMAND"
          
      - name: Framework compatibility check
        run: |
          # Verify existing framework capabilities are preserved
          if [ -d ".claude/modules" ]; then
            echo "‚úÖ Framework modules detected"
            echo "‚úÖ Preserving existing framework capabilities"
          else
            echo "‚ÑπÔ∏è No framework configuration found - standard mode only"
          fi
          
      - name: Comment result on issue
        if: github.event_name == 'issue_comment'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `ü§ñ Claude Code Standard Mode executed successfully!
              
              **Mode**: claude-standard
              **Status**: ‚úÖ Complete
              **Framework**: Preserved existing capabilities
              **Security**: Standard boundaries applied
              
              *Execution completed at ${new Date().toISOString()}*`
            });

  # Enhanced Claude Code with full framework capabilities  
  claude-framework:
    name: 'Claude Code Framework Mode'
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'issue_comment' && 
       contains(github.event.comment.body, '@claude-framework')) ||
      (github.event_name == 'workflow_dispatch' && 
       github.event.inputs.mode == 'claude-framework')
    
    permissions:
      contents: write
      issues: write
      pull-requests: write
      actions: write
      packages: read
      security-events: write
      statuses: write
      
    timeout-minutes: 60
    
    environment: 
      name: claude-framework
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install enhanced dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # Additional dependencies for framework mode
          pip install pytest coverage bandit safety
          
      - name: Install Claude Code CLI (Enhanced)
        run: |
          curl -fsSL https://claude.ai/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          
      - name: Verify Claude Code installation
        run: |
          claude --version
          claude --capabilities
          
      - name: Set up enhanced Claude Code configuration
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Configure Claude Code with enhanced framework capabilities
          claude configure --api-key="$ANTHROPIC_API_KEY" --mode=framework
          
          # Enable all framework capabilities if modules exist
          if [ -d ".claude/modules" ]; then
            echo "üöÄ Enabling full framework capabilities..."
            claude configure --framework-mode=full
          fi
          
      - name: Framework validation
        run: |
          # Validate framework integrity
          echo "üîç Validating AI Variance Whisperer Framework..."
          
          # Check framework version
          if grep -q "$FRAMEWORK_VERSION" CLAUDE.md; then
            echo "‚úÖ Framework version $FRAMEWORK_VERSION confirmed"
          else
            echo "‚ö†Ô∏è Framework version mismatch detected"
          fi
          
          # Validate framework commands
          COMMANDS=(protocol auto rapid scale swarm practical batch fastapi test security production)
          for cmd in "${COMMANDS[@]}"; do
            if [ -f ".claude/commands/$cmd.md" ]; then
              echo "‚úÖ Command /$cmd available"
            else
              echo "‚ùå Command /$cmd missing"
            fi
          done
          
      - name: Extract and validate framework command
        if: github.event_name == 'issue_comment'
        id: extract-framework-command
        run: |
          COMMENT_BODY="${{ github.event.comment.body }}"
          COMMAND=$(echo "$COMMENT_BODY" | grep -oP '@claude-framework\s+\K.*' || echo "/protocol")
          echo "command=$COMMAND" >> $GITHUB_OUTPUT
          
          # Validate command against framework capabilities
          if [[ "$COMMAND" =~ ^/.+ ]]; then
            echo "‚úÖ Framework command detected: $COMMAND"
          else
            echo "‚ÑπÔ∏è Standard command, upgrading to framework mode: $COMMAND"
          fi
          
      - name: Execute Claude Code with framework capabilities
        env:
          CLAUDE_COMMAND: ${{ steps.extract-framework-command.outputs.command || github.event.inputs.comment || '/protocol' }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          echo "üöÄ Executing Claude Code in framework mode..."
          echo "Command: $CLAUDE_COMMAND"
          echo "Framework: AI Variance Whisperer v7.0.0-EMPIRICAL-REALITY-ALIGNED"
          
          # Execute with full framework capabilities
          claude --mode=framework \
                --context=".claude" \
                --preserve-capabilities \
                --enable-multi-agent \
                "$CLAUDE_COMMAND"
          
      - name: Framework compliance check
        run: |
          echo "üîç Running framework compliance checks..."
          
          # TDD compliance verification
          if [ -f ".claude/modules/quality/tdd.md" ]; then
            echo "‚úÖ TDD enforcement module active"
          fi
          
          # Security standards verification
          if [ -f ".claude/modules/quality/honesty-policy.md" ]; then
            echo "‚úÖ Honesty policy module active"
          fi
          
          # Multi-agent coordination check
          if [ -f ".claude/modules/patterns/multi-agent.md" ]; then
            echo "‚úÖ Multi-agent pattern module active"
          fi
          
      - name: Run framework validation tests
        run: |
          # Run framework validation tests
          if [ -d "tests/framework" ]; then
            echo "üß™ Running framework validation tests..."
            python -m pytest tests/framework/ -v --tb=short
          else
            echo "‚ö†Ô∏è Framework tests not found, skipping..."
          fi
          
      - name: Security scan
        run: |
          # Run security scans in framework mode
          if [ -d "src/" ]; then
            bandit -r src/ -f json -o bandit-report.json || true
          else
            echo "‚ö†Ô∏è src/ directory not found, skipping bandit scan"
            echo '{}' > bandit-report.json
          fi
          safety check --json --output safety-report.json || true
          
      - name: Upload framework artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: claude-framework-artifacts
          path: |
            bandit-report.json
            safety-report.json
            .claude/
            
      - name: Comment framework result on issue
        if: github.event_name == 'issue_comment'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `üöÄ Claude Code Framework Mode executed successfully!
              
              **Mode**: claude-framework (Enhanced)
              **Status**: ‚úÖ Complete
              **Framework**: AI Variance Whisperer v7.0.0-EMPIRICAL-REALITY-ALIGNED
              **Capabilities**: All 11 commands available + 3982 permissions
              **Security**: Enterprise-grade boundaries applied
              **Multi-Agent**: Coordination enabled
              
              **Framework Commands Available**:
              \`/protocol\` \`/auto\` \`/rapid\` \`/scale\` \`/swarm\` \`/practical\` \`/batch\` \`/fastapi\` \`/test\` \`/security\` \`/production\`
              
              *Framework execution completed at ${new Date().toISOString()}*`
            });

  # Nightly maintenance and health checks
  claude-maintenance:
    name: 'Claude Code Maintenance'
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && 
       github.event.inputs.mode == 'claude-maintenance')
    
    permissions:
      contents: write
      issues: write
      actions: read
      security-events: write
      
    timeout-minutes: 45
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install maintenance dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest coverage bandit safety pre-commit
          
      - name: Install Claude Code CLI
        run: |
          curl -fsSL https://claude.ai/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          
      - name: Pre-maintenance health check
        run: |
          echo "üè• Running pre-maintenance health monitoring..."
          
          # Run health monitoring script if available
          if [ -f "scripts/monitor_framework_health.py" ]; then
            python scripts/monitor_framework_health.py || echo "‚ö†Ô∏è Health check reported warnings"
          fi
          
      - name: Framework health check
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          echo "üîç Running AI Variance Whisperer Framework health checks..."
          
          # Check framework file integrity
          FRAMEWORK_FILES=(
            "CLAUDE.md"
            ".claude/modules/quality/tdd.md"
            ".claude/modules/quality/honesty-policy.md"
            ".claude/modules/patterns/multi-agent.md"
            ".claude/modules/patterns/session-management.md"
          )
          
          for file in "${FRAMEWORK_FILES[@]}"; do
            if [ -f "$file" ]; then
              echo "‚úÖ $file - OK"
            else
              echo "‚ùå $file - MISSING"
            fi
          done
          
      - name: Run framework validation suite
        run: |
          echo "üß™ Running framework validation tests..."
          
          # Run framework-specific tests
          if [ -d "tests/framework" ]; then
            python -m pytest tests/framework/ -v --tb=short
          fi
          
          # Run any other test suites if available
          if [ -d "tests/unit" ]; then
            python -m pytest tests/unit/ -v --tb=short || true
          fi
          
      - name: Security maintenance scan
        run: |
          echo "üîí Running security maintenance scans..."
          
          # Security dependency check
          safety check --json --output safety-maintenance-report.json || true
          
          # Code security scan
          if [ -d "src/" ]; then
            bandit -r src/ -f json -o bandit-maintenance-report.json || true
          else
            echo "‚ö†Ô∏è src/ directory not found, skipping bandit scan"
            echo '{}' > bandit-maintenance-report.json
          fi
          
          # Framework-specific security checks
          if [ -f "src/security/__init__.py" ]; then
            echo "‚úÖ Security module integrity confirmed"
          fi
          
      - name: Framework metrics collection
        run: |
          echo "üìä Collecting framework metrics..."
          
          # Count framework components
          COMMAND_COUNT=$(find .claude/commands -name "*.md" 2>/dev/null | wc -l || echo "0")
          MODULE_COUNT=$(find .claude/modules -name "*.md" 2>/dev/null | wc -l || echo "0")
          
          echo "üìà Framework Metrics:"
          echo "  Commands: $COMMAND_COUNT"
          echo "  Modules: $MODULE_COUNT"
          echo "  Version: $FRAMEWORK_VERSION"
          
          # Save metrics for reporting
          cat > framework-metrics.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "framework_version": "$FRAMEWORK_VERSION",
            "commands_count": $COMMAND_COUNT,
            "modules_count": $MODULE_COUNT,
            "health_status": "healthy"
          }
          EOF
          
      - name: Update framework documentation
        run: |
          echo "üìö Checking framework documentation currency..."
          
          # Check if documentation needs updates
          LAST_COMMIT_DATE=$(git log -1 --format=%cd --date=iso CLAUDE.md)
          echo "Last CLAUDE.md update: $LAST_COMMIT_DATE"
          
          # Framework documentation health
          if grep -q "v7.0.0-EMPIRICAL-REALITY-ALIGNED" CLAUDE.md; then
            echo "‚úÖ Documentation version current"
          else
            echo "‚ö†Ô∏è Documentation may need version update"
          fi
          
      - name: Create maintenance issue if needed
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® Claude Code Framework Maintenance Alert - ${new Date().toISOString().split('T')[0]}`,
              body: `## Framework Maintenance Alert
              
              **Date**: ${new Date().toISOString()}
              **Status**: ‚ùå Issues detected during maintenance run
              **Framework**: AI Variance Whisperer v7.0.0-EMPIRICAL-REALITY-ALIGNED
              
              ### Action Required
              - Review maintenance workflow logs
              - Verify framework component integrity
              - Check security scan results
              
              ### Automatic Checks Failed
              Please investigate the maintenance workflow failure and ensure framework stability.
              
              **Workflow Run**: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
              
              ---
              *This issue was automatically created by the Claude Code maintenance workflow*`,
              labels: ['maintenance', 'claude-framework', 'priority-high']
            });
            
      - name: Upload maintenance artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: claude-maintenance-artifacts
          path: |
            framework-metrics.json
            safety-maintenance-report.json
            bandit-maintenance-report.json
            
      - name: Maintenance summary
        run: |
          echo "‚úÖ Claude Code Framework maintenance completed"
          echo "üìä Metrics collected and uploaded"
          echo "üîí Security scans completed"
          echo "üß™ Validation tests executed"
          echo "üìö Documentation currency verified"

  # Intelligent Prompt Engineering Review System
  claude-prompt-review:
    name: 'Claude Prompt Engineering Review'
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' ||
      (github.event_name == 'workflow_dispatch' && 
       github.event.inputs.mode == 'claude-prompt-review')
    
    permissions:
      contents: read
      issues: write
      pull-requests: write
      actions: read
      security-events: read
      
    timeout-minutes: 20
    
    outputs:
      review_result: ${{ steps.intelligent-review.outputs.result }}
      risk_score: ${{ steps.risk-assessment.outputs.score }}
      requires_human: ${{ steps.escalation-check.outputs.requires_human }}
      quality_score: ${{ steps.quality-assessment.outputs.score }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # Additional dependencies for prompt analysis
          pip install pytest coverage bandit safety difflib
          # Install bc for floating point calculations
          sudo apt-get update && sudo apt-get install -y bc
          
      - name: Install Claude Code CLI
        run: |
          curl -fsSL https://claude.ai/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          
      - name: Configure Claude Code for prompt review
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          claude configure --api-key="$ANTHROPIC_API_KEY" --mode=framework
          echo "üîç Claude Code configured for intelligent prompt review"
          
      - name: Detect prompt changes
        id: change-detection
        run: |
          echo "üîç Analyzing prompt engineering changes..."
          
          # Get changed files in .claude/ directory
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }}..${{ github.event.pull_request.head.sha }} -- '.claude/**' 'CLAUDE.md' || echo "")
          else
            CHANGED_FILES=$(git diff --name-only HEAD~1 -- '.claude/**' 'CLAUDE.md' || echo "")
          fi
          
          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Classify change types
          COMMAND_CHANGES=$(echo "$CHANGED_FILES" | grep -c ".claude/commands/" || echo "0")
          MODULE_CHANGES=$(echo "$CHANGED_FILES" | grep -c ".claude/modules/" || echo "0")
          QUALITY_CHANGES=$(echo "$CHANGED_FILES" | grep -c ".claude/system/quality/" || echo "0")
          META_CHANGES=$(echo "$CHANGED_FILES" | grep -c ".claude/meta/" || echo "0")
          CLAUDE_MD_CHANGES=$(echo "$CHANGED_FILES" | grep -c "CLAUDE.md" || echo "0")
          
          echo "command_changes=$COMMAND_CHANGES" >> $GITHUB_OUTPUT
          echo "module_changes=$MODULE_CHANGES" >> $GITHUB_OUTPUT
          echo "quality_changes=$QUALITY_CHANGES" >> $GITHUB_OUTPUT
          echo "meta_changes=$META_CHANGES" >> $GITHUB_OUTPUT
          echo "claude_md_changes=$CLAUDE_MD_CHANGES" >> $GITHUB_OUTPUT
          
          TOTAL_CHANGES=$((COMMAND_CHANGES + MODULE_CHANGES + QUALITY_CHANGES + META_CHANGES + CLAUDE_MD_CHANGES))
          echo "total_changes=$TOTAL_CHANGES" >> $GITHUB_OUTPUT
          
          echo "üìä Change Analysis:"
          echo "  ‚Ä¢ Commands: $COMMAND_CHANGES"
          echo "  ‚Ä¢ Modules: $MODULE_CHANGES"
          echo "  ‚Ä¢ Quality: $QUALITY_CHANGES"
          echo "  ‚Ä¢ Meta: $META_CHANGES"
          echo "  ‚Ä¢ CLAUDE.md: $CLAUDE_MD_CHANGES"
          echo "  ‚Ä¢ Total: $TOTAL_CHANGES"
          
      - name: Risk assessment
        id: risk-assessment
        run: |
          echo "‚ö° Performing intelligent risk assessment..."
          
          # Calculate base risk score
          RISK_SCORE=0
          
          # Command changes are medium risk
          COMMAND_CHANGES=${{ steps.change-detection.outputs.command_changes }}
          RISK_SCORE=$((RISK_SCORE + COMMAND_CHANGES * 15))
          
          # Module changes are lower risk
          MODULE_CHANGES=${{ steps.change-detection.outputs.module_changes }}
          RISK_SCORE=$((RISK_SCORE + MODULE_CHANGES * 10))
          
          # Quality system changes are high risk
          QUALITY_CHANGES=${{ steps.change-detection.outputs.quality_changes }}
          RISK_SCORE=$((RISK_SCORE + QUALITY_CHANGES * 25))
          
          # Meta framework changes are very high risk
          META_CHANGES=${{ steps.change-detection.outputs.meta_changes }}
          RISK_SCORE=$((RISK_SCORE + META_CHANGES * 40))
          
          # CLAUDE.md changes are high risk
          CLAUDE_MD_CHANGES=${{ steps.change-detection.outputs.claude_md_changes }}
          RISK_SCORE=$((RISK_SCORE + CLAUDE_MD_CHANGES * 30))
          
          # Cap at 100
          if [ $RISK_SCORE -gt 100 ]; then
            RISK_SCORE=100
          fi
          
          echo "score=$RISK_SCORE" >> $GITHUB_OUTPUT
          
          if [ $RISK_SCORE -ge 60 ]; then
            echo "risk_level=HIGH" >> $GITHUB_OUTPUT
            echo "üî¥ HIGH RISK: Score $RISK_SCORE/100"
          elif [ $RISK_SCORE -ge 30 ]; then
            echo "risk_level=MEDIUM" >> $GITHUB_OUTPUT
            echo "üü° MEDIUM RISK: Score $RISK_SCORE/100"
          else
            echo "risk_level=LOW" >> $GITHUB_OUTPUT
            echo "üü¢ LOW RISK: Score $RISK_SCORE/100"
          fi
          
      - name: Advanced semantic validation using intelligent analyzer
        id: semantic-validation
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          echo "üß† Performing advanced semantic validation..."
          
          # Prepare changed files list
          CHANGED_FILES="${{ steps.change-detection.outputs.changed_files }}"
          echo "$CHANGED_FILES" > changed_files.txt
          
          # Run intelligent prompt change analyzer
          python3 scripts/prompt_change_analyzer.py \
            --repo-root . \
            --changed-files $(echo "$CHANGED_FILES" | tr '\n' ' ') \
            --output analysis_report.md \
            --json > analysis_results.json
          
          ANALYZER_EXIT_CODE=$?
          
          # Extract results
          SEMANTIC_ISSUES=$(python3 -c "import json; data=json.load(open('analysis_results.json')); print(len(data.get('semantic_issues', [])))")
          DEPENDENCY_IMPACTS=$(python3 -c "import json; data=json.load(open('analysis_results.json')); print(len(data.get('dependency_impacts', [])))")
          SECURITY_IMPLICATIONS=$(python3 -c "import json; data=json.load(open('analysis_results.json')); print(len(data.get('security_implications', [])))")
          
          echo "semantic_issues=$SEMANTIC_ISSUES" >> $GITHUB_OUTPUT
          echo "dependency_impacts=$DEPENDENCY_IMPACTS" >> $GITHUB_OUTPUT
          echo "security_implications=$SECURITY_IMPLICATIONS" >> $GITHUB_OUTPUT
          echo "analyzer_exit_code=$ANALYZER_EXIT_CODE" >> $GITHUB_OUTPUT
          
          echo "üìä Analysis Results:"
          echo "  ‚Ä¢ Semantic Issues: $SEMANTIC_ISSUES"
          echo "  ‚Ä¢ Dependency Impacts: $DEPENDENCY_IMPACTS"
          echo "  ‚Ä¢ Security Implications: $SECURITY_IMPLICATIONS"
          echo "  ‚Ä¢ Analyzer Exit Code: $ANALYZER_EXIT_CODE"
          
      - name: Ultra-critical quality assessment using framework scoring
        id: quality-assessment
        run: |
          echo "üìä Running ultra-critical quality assessment using framework scoring system..."
          
          # Prepare changed files list
          CHANGED_FILES="${{ steps.change-detection.outputs.changed_files }}"
          echo "$CHANGED_FILES" > changed_files.txt
          
          # Run quality assessor with analysis results
          python3 scripts/prompt_quality_assessor.py \
            --repo-root . \
            --changed-files $(echo "$CHANGED_FILES" | tr '\n' ' ') \
            --analysis-results analysis_results.json \
            --output quality_report.md \
            --json > quality_results.json
          
          ASSESSOR_EXIT_CODE=$?
          
          # Extract quality score and level
          QUALITY_SCORE=$(python3 -c "import json; data=json.load(open('quality_results.json')); print(data['overall_score'])")
          QUALITY_GRADE=$(python3 -c "import json; data=json.load(open('quality_results.json')); print(data['grade'])")
          
          # Determine quality level based on framework standards (85%+ threshold)
          if [ "$(echo "$QUALITY_SCORE >= 85" | bc -l)" -eq 1 ]; then
            QUALITY_LEVEL="HIGH"
            echo "‚úÖ HIGH QUALITY: Score $QUALITY_SCORE/100 (Grade: $QUALITY_GRADE)"
          elif [ "$(echo "$QUALITY_SCORE >= 70" | bc -l)" -eq 1 ]; then
            QUALITY_LEVEL="MEDIUM"
            echo "‚ö†Ô∏è MEDIUM QUALITY: Score $QUALITY_SCORE/100 (Grade: $QUALITY_GRADE)"
          else
            QUALITY_LEVEL="LOW"
            echo "‚ùå LOW QUALITY: Score $QUALITY_SCORE/100 (Grade: $QUALITY_GRADE)"
          fi
          
          echo "score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
          echo "grade=$QUALITY_GRADE" >> $GITHUB_OUTPUT
          echo "quality_level=$QUALITY_LEVEL" >> $GITHUB_OUTPUT
          echo "assessor_exit_code=$ASSESSOR_EXIT_CODE" >> $GITHUB_OUTPUT
          
          # Display detailed quality metrics
          echo "üìä Quality Assessment Details:"
          python3 -c "
import json
data = json.load(open('quality_results.json'))
for dimension, info in data['dimensions'].items():
    print(f'  ‚Ä¢ {dimension.replace(\"_\", \" \").title()}: {info[\"score\"]}/100 (Weight: {info[\"weight\"]*100}%)')
"
          
          # Show compliance status
          PRODUCTION_READY=$(python3 -c "import json; data=json.load(open('quality_results.json')); print('true' if data['compliance']['production_ready'] else 'false')")
          echo "production_ready=$PRODUCTION_READY" >> $GITHUB_OUTPUT
          
          if [ "$PRODUCTION_READY" = "true" ]; then
            echo "‚úÖ PRODUCTION READY: Meets 85%+ quality threshold"
          else
            echo "‚ùå NOT PRODUCTION READY: Below 85% quality threshold"
          fi
          
      - name: Enhanced escalation decision with ultra-critical scoring
        id: escalation-check
        run: |
          echo "üéØ Determining escalation requirements using ultra-critical quality framework..."
          
          RISK_SCORE=${{ steps.risk-assessment.outputs.score }}
          QUALITY_SCORE=${{ steps.quality-assessment.outputs.score }}
          QUALITY_GRADE="${{ steps.quality-assessment.outputs.grade }}"
          PRODUCTION_READY="${{ steps.quality-assessment.outputs.production_ready }}"
          REVIEW_MODE="${{ github.event.inputs.review_mode || 'auto' }}"
          SEMANTIC_ISSUES=${{ steps.semantic-validation.outputs.semantic_issues }}
          SECURITY_IMPLICATIONS=${{ steps.semantic-validation.outputs.security_implications }}
          
          REQUIRES_HUMAN="false"
          ESCALATION_REASONS=()
          
          # Force manual review mode
          if [ "$REVIEW_MODE" = "manual" ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("Manual review mode requested")
            echo "üë• Manual review mode requested"
          fi
          
          # Force approve mode (for testing/emergency)
          if [ "$REVIEW_MODE" = "force-approve" ]; then
            REQUIRES_HUMAN="false"
            echo "‚ö° Force approve mode - bypassing ALL checks"
            echo "requires_human=$REQUIRES_HUMAN" >> $GITHUB_OUTPUT
            echo "escalation_reasons=" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # CRITICAL: Production readiness check (85%+ threshold from framework)
          if [ "$PRODUCTION_READY" = "false" ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("Below 85% quality threshold - not production ready")
            echo "üö´ CRITICAL: Below 85% quality threshold requires human approval"
          fi
          
          # HIGH RISK: Security implications
          if [ $SECURITY_IMPLICATIONS -gt 0 ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("Security implications detected ($SECURITY_IMPLICATIONS issues)")
            echo "üîí CRITICAL: Security implications require human approval"
          fi
          
          # HIGH RISK: Meta framework changes
          META_CHANGES=${{ steps.change-detection.outputs.meta_changes }}
          if [ $META_CHANGES -gt 0 ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("Meta framework changes detected")
            echo "üß† CRITICAL: Meta framework changes require human approval"
          fi
          
          # HIGH RISK: Overall risk score
          if [ $RISK_SCORE -ge 60 ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("High risk score: $RISK_SCORE/100")
            echo "üî¥ HIGH RISK: Score $RISK_SCORE/100 requires human approval"
          fi
          
          # MEDIUM RISK: Multiple semantic issues
          if [ $SEMANTIC_ISSUES -gt 3 ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("Multiple semantic issues: $SEMANTIC_ISSUES")
            echo "‚ö†Ô∏è Multiple semantic issues require human review"
          fi
          
          # QUALITY CHECK: Framework quality standards
          if [ "$(echo "$QUALITY_SCORE < 70" | bc -l)" -eq 1 ]; then
            REQUIRES_HUMAN="true"
            ESCALATION_REASONS+=("Quality score below acceptable threshold: $QUALITY_SCORE/100")
            echo "‚ùå Quality score $QUALITY_SCORE/100 requires human approval"
          fi
          
          # Join escalation reasons
          IFS='; ' ESCALATION_REASONS_STRING="${ESCALATION_REASONS[*]}"
          
          echo "requires_human=$REQUIRES_HUMAN" >> $GITHUB_OUTPUT
          echo "escalation_reasons=$ESCALATION_REASONS_STRING" >> $GITHUB_OUTPUT
          echo "escalation_count=${#ESCALATION_REASONS[@]}" >> $GITHUB_OUTPUT
          
          if [ "$REQUIRES_HUMAN" = "true" ]; then
            echo "üë• HUMAN REVIEW REQUIRED - ${#ESCALATION_REASONS[@]} reasons:"
            for reason in "${ESCALATION_REASONS[@]}"; do
              echo "  ‚Ä¢ $reason"
            done
          else
            echo "ü§ñ AUTOMATED APPROVAL POSSIBLE"
            echo "‚úÖ Quality: $QUALITY_SCORE/100 ($QUALITY_GRADE)"
            echo "‚úÖ Risk: $RISK_SCORE/100"
            echo "‚úÖ Production Ready: $PRODUCTION_READY"
          fi
          
      - name: Intelligent review decision with ultra-critical standards
        id: intelligent-review
        run: |
          echo "üéØ Making intelligent review decision using ultra-critical quality framework..."
          
          REQUIRES_HUMAN=${{ steps.escalation-check.outputs.requires_human }}
          ESCALATION_REASONS="${{ steps.escalation-check.outputs.escalation_reasons }}"
          ESCALATION_COUNT=${{ steps.escalation-check.outputs.escalation_count }}
          RISK_SCORE=${{ steps.risk-assessment.outputs.score }}
          QUALITY_SCORE=${{ steps.quality-assessment.outputs.score }}
          QUALITY_GRADE="${{ steps.quality-assessment.outputs.grade }}"
          PRODUCTION_READY="${{ steps.quality-assessment.outputs.production_ready }}"
          
          if [ "$REQUIRES_HUMAN" = "true" ]; then
            echo "result=REQUIRES_HUMAN_REVIEW" >> $GITHUB_OUTPUT
            echo "confidence=HIGH" >> $GITHUB_OUTPUT
            echo "üë• Result: Human review required"
            echo "üìã Escalation Count: $ESCALATION_COUNT"
            echo "üìù Reasons: $ESCALATION_REASONS"
          else
            # Ultra-critical standards: Only auto-approve if meeting production threshold
            if [ "$PRODUCTION_READY" = "true" ] && [ $RISK_SCORE -lt 30 ]; then
              echo "result=AUTO_APPROVED" >> $GITHUB_OUTPUT
              echo "confidence=HIGH" >> $GITHUB_OUTPUT
              echo "‚úÖ Result: Automatically approved"
              echo "üìä Quality: $QUALITY_SCORE/100 ($QUALITY_GRADE) - Production Ready"
              echo "üéØ Risk: $RISK_SCORE/100 - Low Risk"
            elif [ "$PRODUCTION_READY" = "true" ] && [ $RISK_SCORE -lt 60 ]; then
              echo "result=AUTO_APPROVED_WITH_MONITORING" >> $GITHUB_OUTPUT
              echo "confidence=MEDIUM" >> $GITHUB_OUTPUT
              echo "‚ö†Ô∏è Result: Approved with enhanced monitoring"
              echo "üìä Quality: $QUALITY_SCORE/100 ($QUALITY_GRADE) - Production Ready"
              echo "üéØ Risk: $RISK_SCORE/100 - Medium Risk"
            else
              # This shouldn't happen with proper escalation logic, but safety fallback
              echo "result=REQUIRES_HUMAN_REVIEW" >> $GITHUB_OUTPUT
              echo "confidence=LOW" >> $GITHUB_OUTPUT
              echo "üîç Result: Fallback to human review"
              echo "‚ö†Ô∏è Unexpected state: Production Ready=$PRODUCTION_READY, Risk=$RISK_SCORE"
            fi
          fi
          
          # Log decision reasoning
          echo "üß† Decision Reasoning:"
          echo "  ‚Ä¢ Quality Score: $QUALITY_SCORE/100 ($QUALITY_GRADE)"
          echo "  ‚Ä¢ Production Ready: $PRODUCTION_READY"
          echo "  ‚Ä¢ Risk Score: $RISK_SCORE/100"
          echo "  ‚Ä¢ Escalation Required: $REQUIRES_HUMAN"
          if [ "$REQUIRES_HUMAN" = "true" ]; then
            echo "  ‚Ä¢ Escalation Reasons: $ESCALATION_REASONS"
          fi
          
      - name: Generate comprehensive review summary
        id: summary
        run: |
          echo "üìã Generating comprehensive review summary with ultra-critical quality analysis..."
          
          # Create detailed summary with enhanced quality assessment
          cat > review_summary.md << EOF
          # üîç Ultra-Critical Prompt Engineering Review Summary
          
          **Review Date**: $(date '+%Y-%m-%d %H:%M:%S UTC')
          **PR/Commit**: ${{ github.event.pull_request.number || 'Manual' }}
          **Framework Version**: ${{ env.FRAMEWORK_VERSION }}
          **Review Confidence**: ${{ steps.intelligent-review.outputs.confidence || 'MEDIUM' }}
          
          ## üìä Ultra-Critical Quality Assessment
          
          | Metric | Score | Level | Status |
          |--------|-------|-------|--------|
          | **Overall Quality** | **${{ steps.quality-assessment.outputs.score }}/100** | **${{ steps.quality-assessment.outputs.grade }}** | ${{ steps.quality-assessment.outputs.production_ready == 'true' && '‚úÖ Production Ready' || '‚ùå Not Production Ready' }} |
          | Risk Score | ${{ steps.risk-assessment.outputs.score }}/100 | ${{ steps.risk-assessment.outputs.risk_level }} | ${{ steps.risk-assessment.outputs.score < 30 && '‚úÖ Low Risk' || steps.risk-assessment.outputs.score < 60 && '‚ö†Ô∏è Medium Risk' || 'üî¥ High Risk' }} |
          
          ### üìà Quality Dimension Breakdown
          EOF
          
          # Add quality dimensions from JSON output
          python3 -c "
import json
data = json.load(open('quality_results.json'))
print('| Dimension | Score | Weight | Assessment |')
print('|-----------|-------|--------|------------|')
for dimension, info in data['dimensions'].items():
    status = '‚úÖ Excellent' if info['score'] >= 90 else '‚úÖ Good' if info['score'] >= 85 else '‚ö†Ô∏è Acceptable' if info['score'] >= 70 else '‚ùå Poor'
    print(f'| {dimension.replace(\"_\", \" \").title()} | {info[\"score\"]}/100 | {info[\"weight\"]*100:.0f}% | {status} |')
print()
" >> review_summary.md
          
          cat >> review_summary.md << EOF
          ## üîç Change Analysis
          
          **Files Changed**: ${{ steps.change-detection.outputs.total_changes }}
          - **Commands**: ${{ steps.change-detection.outputs.command_changes }} ${{ steps.change-detection.outputs.command_changes > 0 && '‚ö†Ô∏è' || '‚úÖ' }}
          - **Modules**: ${{ steps.change-detection.outputs.module_changes }} ${{ steps.change-detection.outputs.module_changes > 0 && 'üì¶' || '‚úÖ' }}
          - **Quality System**: ${{ steps.change-detection.outputs.quality_changes }} ${{ steps.change-detection.outputs.quality_changes > 0 && 'üî¥ High Risk' || '‚úÖ' }}
          - **Meta Framework**: ${{ steps.change-detection.outputs.meta_changes }} ${{ steps.change-detection.outputs.meta_changes > 0 && 'üö® Critical' || '‚úÖ' }}
          - **CLAUDE.md**: ${{ steps.change-detection.outputs.claude_md_changes }} ${{ steps.change-detection.outputs.claude_md_changes > 0 && '‚ö†Ô∏è' || '‚úÖ' }}
          
          ## üß† Semantic & Security Analysis
          
          - **Semantic Issues**: ${{ steps.semantic-validation.outputs.semantic_issues }} ${{ steps.semantic-validation.outputs.semantic_issues > 0 && '‚ö†Ô∏è' || '‚úÖ' }}
          - **Dependency Impacts**: ${{ steps.semantic-validation.outputs.dependency_impacts }} ${{ steps.semantic-validation.outputs.dependency_impacts > 0 && 'üîó' || '‚úÖ' }}
          - **Security Implications**: ${{ steps.semantic-validation.outputs.security_implications }} ${{ steps.semantic-validation.outputs.security_implications > 0 && 'üîí Critical' || '‚úÖ' }}
          
          ## üéØ Review Decision
          
          **Final Result**: **${{ steps.intelligent-review.outputs.result }}**
          **Human Review Required**: ${{ steps.escalation-check.outputs.requires_human == 'true' && 'üë• Yes' || 'ü§ñ No' }}
          
          EOF
          
          # Add escalation reasons if human review required
          ESCALATION_REASONS="${{ steps.escalation-check.outputs.escalation_reasons }}"
          if [ "${{ steps.escalation-check.outputs.requires_human }}" = "true" ]; then
            cat >> review_summary.md << EOF
          ### üìã Escalation Reasons (${{ steps.escalation-check.outputs.escalation_count }} total)
          EOF
            echo "$ESCALATION_REASONS" | tr ';' '\n' | while read -r reason; do
              [ -n "$reason" ] && echo "- $reason" >> review_summary.md
            done
            echo "" >> review_summary.md
          fi
          
          cat >> review_summary.md << EOF
          ## üõ°Ô∏è Safety & Compliance Framework
          
          - ‚úÖ **Ultra-Critical Quality Scoring**: 85%+ threshold enforced
          - ‚úÖ **Atomic Rollback Protocol**: Available for instant recovery
          - ‚úÖ **Framework Safety Boundaries**: Enforced with meta-framework protection
          - ‚úÖ **Quality Gates Validation**: 6-dimensional assessment completed
          - ‚úÖ **Risk Assessment**: Multi-tier analysis performed
          - ‚úÖ **Semantic Validation**: Advanced analysis with dependency checking
          - ‚úÖ **Production Standards**: Enterprise-grade compliance verification
          
          ## üìä Compliance Status
          
          EOF
          
          # Add compliance details from quality assessment
          python3 -c "
import json
data = json.load(open('quality_results.json'))
compliance = data['compliance']
for key, value in compliance.items():
    status = '‚úÖ' if value else '‚ùå'
    label = key.replace('_', ' ').title()
    print(f'- {status} **{label}**: {\"Met\" if value else \"Not Met\"}')
" >> review_summary.md
          
          cat >> review_summary.md << EOF
          
          ---
          *ü§ñ Generated by Claude Ultra-Critical Prompt Engineering Review System v3.0*
          *üî¨ Powered by Framework Meta-Prompting Orchestration Engine*
          EOF
          
          echo "‚úÖ Comprehensive review summary generated successfully"
          
          # Display key metrics
          echo "üìä Key Review Metrics:"
          echo "  ‚Ä¢ Quality Score: ${{ steps.quality-assessment.outputs.score }}/100 (${{ steps.quality-assessment.outputs.grade }})"
          echo "  ‚Ä¢ Production Ready: ${{ steps.quality-assessment.outputs.production_ready }}"
          echo "  ‚Ä¢ Risk Score: ${{ steps.risk-assessment.outputs.score }}/100"
          echo "  ‚Ä¢ Human Review: ${{ steps.escalation-check.outputs.requires_human }}"
          echo "  ‚Ä¢ Final Decision: ${{ steps.intelligent-review.outputs.result }}"
          
      - name: Post review results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('review_summary.md', 'utf8');
            
            const reviewResult = '${{ steps.intelligent-review.outputs.result }}';
            const requiresHuman = '${{ steps.escalation-check.outputs.requires_human }}' === 'true';
            
            let emoji = '‚úÖ';
            let status = 'Approved';
            
            if (requiresHuman) {
              emoji = 'üë•';
              status = 'Human Review Required';
            } else if (reviewResult === 'AUTO_APPROVED_WITH_MONITORING') {
              emoji = '‚ö†Ô∏è';
              status = 'Approved with Monitoring';
            }
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `${emoji} **Prompt Engineering Review: ${status}**\n\n${summary}`
            });
            
            // If human review required, create a review request
            if (requiresHuman) {
              await github.rest.pulls.createReview({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: context.issue.number,
                event: 'REQUEST_CHANGES',
                body: 'üë• This prompt engineering change requires human review due to complexity or risk factors. Please review the analysis above and approve manually if acceptable.'
              });
            }
            
      - name: Upload comprehensive review artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: prompt-review-artifacts-${{ github.run_number }}
          path: |
            review_summary.md
            quality_report.md
            quality_results.json
            analysis_report.md
            analysis_results.json
            changed_files.txt
          retention-days: 30